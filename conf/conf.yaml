# coding:utf-8
time_out: 200                  # timeout for crawling and storing user info
min_crawl_interal: 10           # min interal of http request
max_crawl_interal: 20           # max interal of http request
excp_interal: 5*60             # time for sleeping when crawling raises exceptions


db:
    host: localhost
    port: 3306
    user: root
    password: 123456
    db_name: ip_list
    db_type: mysql

redis:
    host: localhost
    port: 6379
    password: ''
    cookies: 1                   # store and fetch cookies
    # store fetched urls and results,so you can decide whether retry to crawl the urls or not
    urls: 2
    broker: 5                    # broker for celery
    backend: 6                   # backed for celery
    id_name: 8                   # user id and namesï¼Œfor repost info analysis
    # expire_time (hours) for redis db2, if they are useless to you, you can set the value smaller
    expire_time: 48
